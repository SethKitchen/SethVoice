{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b25ac2-b18a-443d-9891-43c63a6d00b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:True\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:45\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " | > Found 13100 files in /root/tts-output/LJSpeech-1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " > Training Environment:\n",
      " | > Backend: Torch\n",
      " | > Mixed precision: True\n",
      " | > Precision: fp16\n",
      " | > Current device: 0\n",
      " | > Num. of GPUs: 1\n",
      " | > Num. of CPUs: 24\n",
      " | > Num. of Torch Threads: 12\n",
      " | > Torch seed: 54321\n",
      " | > Torch CUDNN: True\n",
      " | > Torch CUDNN deterministic: False\n",
      " | > Torch CUDNN benchmark: False\n",
      " | > Torch TF32 MatMul: False\n",
      " > Start Tensorboard: tensorboard --logdir=/root/tts-output/run-July-25-2023_05+10PM-0000000\n",
      "\n",
      " > Model has 28610257 parameters\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 0/1000\u001b[0m\n",
      " --> /root/tts-output/run-July-25-2023_05+10PM-0000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Pre-computing phonemes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|‚ñå                                                                               | 86/12969 [00:01<03:54, 54.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "√∞…ô k…ômÀà…™ É…ôn b·µªlÀàiÀêvz √∞√¶t√∞…ô fÀà√¶kts  åv√∞…™ …êsÀå√¶s·µªnÀàe…™ É…ôn  åv p…πÀà…õz…™d…ônt kÀà…õn…ôdi pÀà…î…™nt t…ô sÀà…úÀê înÃ© mÀà…õ í…öz wÀà…™t É,\n",
      " [!] Character 'Ã©' not found in the vocabulary. Discarding it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                 | 2062/12969 [00:41<03:57, 45.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Àà…™nt ä √∞…ô ‚Äúk…πÀàe…™…æ…ö‚Äù dÀà å…° Ààa ät …™n√∞…ô mÀà…™d…ôl, pÀàoÀê…π √∞…ô spÀà ånd í, wÀà…îÀê…πm wÀà…îÀê…æ…ö, √∞…ô m…ôlÀà√¶s·µªz, √¶nd sÀào äd…ô d…™sÀà…ëÀêlvd …™n hÀà…ëÀêt wÀà…îÀê…æ…ö.\n",
      " [!] Character '‚Äú' not found in the vocabulary. Discarding it.\n",
      "Àà…™nt ä √∞…ô ‚Äúk…πÀàe…™…æ…ö‚Äù dÀà å…° Ààa ät …™n√∞…ô mÀà…™d…ôl, pÀàoÀê…π √∞…ô spÀà ånd í, wÀà…îÀê…πm wÀà…îÀê…æ…ö, √∞…ô m…ôlÀà√¶s·µªz, √¶nd sÀào äd…ô d…™sÀà…ëÀêlvd …™n hÀà…ëÀêt wÀà…îÀê…æ…ö.\n",
      " [!] Character '‚Äù' not found in the vocabulary. Discarding it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12969/12969 [04:22<00:00, 49.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: False\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: True\n",
      "\t| > phonemizer:\n",
      "\t\t| > phoneme language: en-us\n",
      "\t\t| > phoneme backend: espeak\n",
      "\t| > 3 not found characters:\n",
      "\t| > Ã©\n",
      "\t| > ‚Äú\n",
      "\t| > ‚Äù\n",
      "| > Number of instances : 12969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m > TRAINING (2023-07-25 17:15:09) \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Preprocessing samples\n",
      " | > Max text length: 188\n",
      " | > Min text length: 13\n",
      " | > Avg text length: 100.90014650319993\n",
      " | \n",
      " | > Max audio length: 222643.0\n",
      " | > Min audio length: 24499.0\n",
      " | > Avg audio length: 144984.29755570978\n",
      " | > Num. instances discarded samples: 0\n",
      " | > Batch group size: 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:309: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "\n",
      "\u001b[1m   --> TIME: 2023-07-25 17:15:14 -- STEP: 0/406 -- GLOBAL_STEP: 0\u001b[0m\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 3.9744  (3.974362373352051)\n",
      "     | > loader_time: 1.449  (1.4489879608154297)\n",
      "\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
      "\n",
      "\u001b[1m   --> TIME: 2023-07-25 17:15:25 -- STEP: 25/406 -- GLOBAL_STEP: 25\u001b[0m\n",
      "     | > loss: 3.484445810317993  (3.429475116729736)\n",
      "     | > log_mle: 0.8619254231452942  (0.8586624264717102)\n",
      "     | > loss_dur: 2.6225204467773438  (2.570812702178955)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.4461, device='cuda:0')  (tensor(8.7687, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.5189  (0.4362503623962402)\n",
      "     | > loader_time: 0.0028  (2.4853636550903313)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2023-07-25 17:15:37 -- STEP: 50/406 -- GLOBAL_STEP: 50\u001b[0m\n",
      "     | > loss: 3.5152974128723145  (3.4209841668605803)\n",
      "     | > log_mle: 0.861578643321991  (0.8602354019880295)\n",
      "     | > loss_dur: 2.6537187099456787  (2.5607487618923193)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.5797, device='cuda:0')  (tensor(9.1662, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4647  (0.45973947525024417)\n",
      "     | > loader_time: 0.0067  (1.244677538871765)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2023-07-25 17:15:51 -- STEP: 75/406 -- GLOBAL_STEP: 75\u001b[0m\n",
      "     | > loss: 3.4860024452209473  (3.423164327328022)\n",
      "     | > log_mle: 0.8706484436988831  (0.8610439126308148)\n",
      "     | > loss_dur: 2.615354061126709  (2.5621204119462244)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.5389, device='cuda:0')  (tensor(9.2738, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.397  (0.4855929183959961)\n",
      "     | > loader_time: 0.0089  (0.8317604287465411)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2023-07-25 17:16:05 -- STEP: 100/406 -- GLOBAL_STEP: 100\u001b[0m\n",
      "     | > loss: 3.3659017086029053  (3.4202122926712035)\n",
      "     | > log_mle: 0.8662928938865662  (0.861510905292299)\n",
      "     | > loss_dur: 2.4996087551116943  (2.5587013880411806)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.2692, device='cuda:0')  (tensor(9.3119, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.3902  (0.5012412738800048)\n",
      "     | > loader_time: 0.0045  (0.6255580401420592)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2023-07-25 17:16:19 -- STEP: 125/406 -- GLOBAL_STEP: 125\u001b[0m\n",
      "     | > loss: 3.3690595626831055  (3.4182691325312073)\n",
      "     | > log_mle: 0.868945837020874  (0.8617464143296947)\n",
      "     | > loss_dur: 2.5001137256622314  (2.556522719756418)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.2243, device='cuda:0')  (tensor(9.3331, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.9003  (0.5112462539672852)\n",
      "     | > loader_time: 0.004  (0.5015060482025147)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2023-07-25 17:16:34 -- STEP: 150/406 -- GLOBAL_STEP: 150\u001b[0m\n",
      "     | > loss: 3.389702796936035  (3.4206737518310546)\n",
      "     | > log_mle: 0.8650110960006714  (0.8619540095329284)\n",
      "     | > loss_dur: 2.5246918201446533  (2.5587197457041073)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.3115, device='cuda:0')  (tensor(9.3509, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.7399  (0.5239209508895875)\n",
      "     | > loader_time: 0.0414  (0.41910862922668446)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2023-07-25 17:16:47 -- STEP: 175/406 -- GLOBAL_STEP: 175\u001b[0m\n",
      "     | > loss: 3.442167043685913  (3.421282175815467)\n",
      "     | > log_mle: 0.8622521758079529  (0.8620776494344076)\n",
      "     | > loss_dur: 2.5799148082733154  (2.559204524936099)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.4678, device='cuda:0')  (tensor(9.3605, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6892  (0.5241285106113979)\n",
      "     | > loader_time: 0.0044  (0.3600553716932023)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2023-07-25 17:17:03 -- STEP: 200/406 -- GLOBAL_STEP: 200\u001b[0m\n",
      "     | > loss: 3.409653663635254  (3.4221608224668)\n",
      "     | > log_mle: 0.8661783337593079  (0.8622685416748649)\n",
      "     | > loss_dur: 2.543475389480591  (2.559892281733063)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.4250, device='cuda:0')  (tensor(9.3672, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4504  (0.5372914266586304)\n",
      "     | > loader_time: 0.0039  (0.3160864770412446)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2023-07-25 17:17:18 -- STEP: 225/406 -- GLOBAL_STEP: 225\u001b[0m\n",
      "     | > loss: 3.432549238204956  (3.4212845369826916)\n",
      "     | > log_mle: 0.8609304428100586  (0.8625039289163988)\n",
      "     | > loss_dur: 2.5716187953948975  (2.5587806113930656)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.3956, device='cuda:0')  (tensor(9.3673, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.8196  (0.5432430066002736)\n",
      "     | > loader_time: 0.0041  (0.28185449282328306)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2023-07-25 17:17:34 -- STEP: 250/406 -- GLOBAL_STEP: 250\u001b[0m\n",
      "     | > loss: 3.4777274131774902  (3.42101282676061)\n",
      "     | > log_mle: 0.8684799671173096  (0.8627531399329503)\n",
      "     | > loss_dur: 2.6092474460601807  (2.5582596898078935)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.4375, device='cuda:0')  (tensor(9.3667, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.565  (0.5492654371261595)\n",
      "     | > loader_time: 0.0041  (0.2546705322265626)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2023-07-25 17:17:51 -- STEP: 275/406 -- GLOBAL_STEP: 275\u001b[0m\n",
      "     | > loss: 3.411804676055908  (3.420811740407404)\n",
      "     | > log_mle: 0.8652524352073669  (0.8626713858460481)\n",
      "     | > loss_dur: 2.5465521812438965  (2.55814035613582)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.3124, device='cuda:0')  (tensor(9.3653, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.5566  (0.5602098863775078)\n",
      "     | > loader_time: 0.0044  (0.2322444248199464)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2023-07-25 17:18:07 -- STEP: 300/406 -- GLOBAL_STEP: 300\u001b[0m\n",
      "     | > loss: 3.3955602645874023  (3.4193706602885814)\n",
      "     | > log_mle: 0.8607151508331299  (0.8626917882212276)\n",
      "     | > loss_dur: 2.5348451137542725  (2.5566788739171535)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.2553, device='cuda:0')  (tensor(9.3589, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6767  (0.5680516616503394)\n",
      "     | > loader_time: 0.0045  (0.2135162361462912)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2023-07-25 17:18:25 -- STEP: 325/406 -- GLOBAL_STEP: 325\u001b[0m\n",
      "     | > loss: 3.3861942291259766  (3.418398810189868)\n",
      "     | > log_mle: 0.8630000352859497  (0.8626551221287438)\n",
      "     | > loss_dur: 2.5231943130493164  (2.555743690520999)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.2418, device='cuda:0')  (tensor(9.3527, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.8755  (0.5769849094977741)\n",
      "     | > loader_time: 0.0429  (0.19795642192547147)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2023-07-25 17:18:42 -- STEP: 350/406 -- GLOBAL_STEP: 350\u001b[0m\n",
      "     | > loss: 3.3621160984039307  (3.419002462835873)\n",
      "     | > log_mle: 0.8601388335227966  (0.8626833552823345)\n",
      "     | > loss_dur: 2.5019772052764893  (2.5563191077288483)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.1483, device='cuda:0')  (tensor(9.3486, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.6334  (0.584626836776733)\n",
      "     | > loader_time: 0.0045  (0.18446175711495544)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2023-07-25 17:19:00 -- STEP: 375/406 -- GLOBAL_STEP: 375\u001b[0m\n",
      "     | > loss: 3.448864459991455  (3.4169175918788124)\n",
      "     | > log_mle: 0.8602425456047058  (0.8625946667096385)\n",
      "     | > loss_dur: 2.5886218547821045  (2.554322924026074)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.3180, device='cuda:0')  (tensor(9.3383, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.8516  (0.5931166782379149)\n",
      "     | > loader_time: 0.0192  (0.17284322929382331)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2023-07-25 17:19:19 -- STEP: 400/406 -- GLOBAL_STEP: 400\u001b[0m\n",
      "     | > loss: 3.398013114929199  (3.4147855911499416)\n",
      "     | > log_mle: 0.861301064491272  (0.8626151280525401)\n",
      "     | > loss_dur: 2.5367119312286377  (2.552170462486073)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.1978, device='cuda:0')  (tensor(9.3268, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.395  (0.6017644524574279)\n",
      "     | > loader_time: 0.0042  (0.16270942628383644)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: False\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: True\n",
      "\t| > phonemizer:\n",
      "\t\t| > phoneme language: en-us\n",
      "\t\t| > phoneme backend: espeak\n",
      "\t| > 3 not found characters:\n",
      "\t| > Ã©\n",
      "\t| > ‚Äú\n",
      "\t| > ‚Äù\n",
      "| > Number of instances : 131\n",
      " | > Preprocessing samples\n",
      " | > Max text length: 174\n",
      " | > Min text length: 20\n",
      " | > Avg text length: 100.76335877862596\n",
      " | \n",
      " | > Max audio length: 222643.0\n",
      " | > Min audio length: 34739.0\n",
      " | > Avg audio length: 144033.41221374046\n",
      " | > Num. instances discarded samples: 0\n",
      " | > Batch group size: 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time: 0.11794063448905945 \u001b[0m(+0)\n",
      "     | > avg_loss: 3.403439462184906 \u001b[0m(+0)\n",
      "     | > avg_log_mle: 0.8592553213238716 \u001b[0m(+0)\n",
      "     | > avg_loss_dur: 2.5441841781139374 \u001b[0m(+0)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time: 0.11794063448905945 \u001b[0m(+0.0)\n",
      "     | > avg_loss: 3.403439462184906 \u001b[0m(+0.0)\n",
      "     | > avg_log_mle: 0.8592553213238716 \u001b[0m(+0.0)\n",
      "     | > avg_loss_dur: 2.5441841781139374 \u001b[0m(+0.0)\n",
      "\n",
      " > BEST MODEL : /root/tts-output/run-July-25-2023_05+10PM-0000000/best_model_406.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 1/1000\u001b[0m\n",
      " --> /root/tts-output/run-July-25-2023_05+10PM-0000000\n",
      "\n",
      "\u001b[1m > TRAINING (2023-07-25 17:19:38) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2023-07-25 17:19:48 -- STEP: 19/406 -- GLOBAL_STEP: 425\u001b[0m\n",
      "     | > loss: 3.340238094329834  (3.39993731599105)\n",
      "     | > log_mle: 0.8539333343505859  (0.8522215516943681)\n",
      "     | > loss_dur: 2.486304759979248  (2.547715764296682)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.0524, device='cuda:0')  (tensor(9.0390, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.3899  (0.4352801849967555)\n",
      "     | > loader_time: 0.0046  (0.004071059979890522)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2023-07-25 17:19:59 -- STEP: 44/406 -- GLOBAL_STEP: 450\u001b[0m\n",
      "     | > loss: 3.2834043502807617  (3.355068867856806)\n",
      "     | > log_mle: 0.8573683500289917  (0.854355971921574)\n",
      "     | > loss_dur: 2.4260361194610596  (2.5007128986445335)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.8573, device='cuda:0')  (tensor(8.9703, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4933  (0.43168246204202826)\n",
      "     | > loader_time: 0.0032  (0.004340491511605003)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2023-07-25 17:20:10 -- STEP: 69/406 -- GLOBAL_STEP: 475\u001b[0m\n",
      "     | > loss: 3.3940298557281494  (3.3524207101351977)\n",
      "     | > log_mle: 0.8635463714599609  (0.8554483073345127)\n",
      "     | > loss_dur: 2.5304834842681885  (2.496972401936849)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(9.0259, device='cuda:0')  (tensor(8.9684, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.8412  (0.4421311426853788)\n",
      "     | > loader_time: 0.0056  (0.004344750141751941)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2023-07-25 17:20:22 -- STEP: 94/406 -- GLOBAL_STEP: 500\u001b[0m\n",
      "     | > loss: 3.3148365020751953  (3.3458269733063717)\n",
      "     | > log_mle: 0.8593295812606812  (0.8558096289634703)\n",
      "     | > loss_dur: 2.4555070400238037  (2.4900173456110846)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.8705, device='cuda:0')  (tensor(8.9522, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.7048  (0.4497981198290561)\n",
      "     | > loader_time: 0.0057  (0.004820260595768058)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2023-07-25 17:20:35 -- STEP: 119/406 -- GLOBAL_STEP: 525\u001b[0m\n",
      "     | > loss: 3.3550684452056885  (3.3407598864130614)\n",
      "     | > log_mle: 0.8554665446281433  (0.8561425299203695)\n",
      "     | > loss_dur: 2.4996018409729004  (2.48461735749445)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.9401, device='cuda:0')  (tensor(8.9349, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.3386  (0.45756049116118613)\n",
      "     | > loader_time: 0.0068  (0.005304062065957976)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2023-07-25 17:20:48 -- STEP: 144/406 -- GLOBAL_STEP: 550\u001b[0m\n",
      "     | > loss: 3.2998082637786865  (3.3397303687201596)\n",
      "     | > log_mle: 0.8555009961128235  (0.8563268606861432)\n",
      "     | > loss_dur: 2.444307327270508  (2.483403508861859)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.7622, device='cuda:0')  (tensor(8.9195, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.5963  (0.46999353501531815)\n",
      "     | > loader_time: 0.0038  (0.005440226859516567)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2023-07-25 17:21:01 -- STEP: 169/406 -- GLOBAL_STEP: 575\u001b[0m\n",
      "     | > loss: 3.3597512245178223  (3.3375451183883396)\n",
      "     | > log_mle: 0.8651574850082397  (0.8564405857458622)\n",
      "     | > loss_dur: 2.494593620300293  (2.481104530526336)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.8329, device='cuda:0')  (tensor(8.9013, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4794  (0.47532454891317694)\n",
      "     | > loader_time: 0.0045  (0.005721329231939369)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2023-07-25 17:21:15 -- STEP: 194/406 -- GLOBAL_STEP: 600\u001b[0m\n",
      "     | > loss: 3.3344688415527344  (3.335156854894972)\n",
      "     | > log_mle: 0.8613080978393555  (0.8564818873233402)\n",
      "     | > loss_dur: 2.473160743713379  (2.4786749648064683)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.7278, device='cuda:0')  (tensor(8.8794, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.5859  (0.4836581859391989)\n",
      "     | > loader_time: 0.0039  (0.006163237021141442)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2023-07-25 17:21:29 -- STEP: 219/406 -- GLOBAL_STEP: 625\u001b[0m\n",
      "     | > loss: 3.2610154151916504  (3.3306895042663296)\n",
      "     | > log_mle: 0.8604521751403809  (0.8565982849630591)\n",
      "     | > loss_dur: 2.4005632400512695  (2.474091218486769)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.5429, device='cuda:0')  (tensor(8.8527, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.7175  (0.49092262194036895)\n",
      "     | > loader_time: 0.0041  (0.006418098597766054)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2023-07-25 17:21:42 -- STEP: 244/406 -- GLOBAL_STEP: 650\u001b[0m\n",
      "     | > loss: 3.2950778007507324  (3.3290350515334333)\n",
      "     | > log_mle: 0.8543803095817566  (0.8567477022526694)\n",
      "     | > loss_dur: 2.440697431564331  (2.4722873480593575)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.5693, device='cuda:0')  (tensor(8.8302, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4676  (0.4932396148071914)\n",
      "     | > loader_time: 0.0043  (0.006686167638809952)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2023-07-25 17:21:57 -- STEP: 269/406 -- GLOBAL_STEP: 675\u001b[0m\n",
      "     | > loss: 3.2779042720794678  (3.325977198696491)\n",
      "     | > log_mle: 0.8624767661094666  (0.8566005593338863)\n",
      "     | > loss_dur: 2.4154274463653564  (2.4693766393626047)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.4762, device='cuda:0')  (tensor(8.8054, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.7439  (0.5028632006237498)\n",
      "     | > loader_time: 0.0149  (0.007255480635121851)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2023-07-25 17:22:13 -- STEP: 294/406 -- GLOBAL_STEP: 700\u001b[0m\n",
      "     | > loss: 3.2784719467163086  (3.323203199574737)\n",
      "     | > log_mle: 0.8563957810401917  (0.856521901832957)\n",
      "     | > loss_dur: 2.4220762252807617  (2.4666812979445165)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.4538, device='cuda:0')  (tensor(8.7792, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.7315  (0.5123697048952789)\n",
      "     | > loader_time: 0.0045  (0.007330232737015704)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2023-07-25 17:22:28 -- STEP: 319/406 -- GLOBAL_STEP: 725\u001b[0m\n",
      "     | > loss: 3.2788639068603516  (3.3194602522356758)\n",
      "     | > log_mle: 0.8509849905967712  (0.8563897372413205)\n",
      "     | > loss_dur: 2.4278788566589355  (2.4630705136864157)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.3802, device='cuda:0')  (tensor(8.7506, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4386  (0.5185387366244038)\n",
      "     | > loader_time: 0.0065  (0.007535326069798961)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2023-07-25 17:22:45 -- STEP: 344/406 -- GLOBAL_STEP: 750\u001b[0m\n",
      "     | > loss: 3.272627353668213  (3.317559233238531)\n",
      "     | > log_mle: 0.8531981706619263  (0.8562870481333067)\n",
      "     | > loss_dur: 2.419429063796997  (2.461272184238877)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.3470, device='cuda:0')  (tensor(8.7244, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.4756  (0.5279717466165854)\n",
      "     | > loader_time: 0.0126  (0.0076701918313669595)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2023-07-25 17:23:01 -- STEP: 369/406 -- GLOBAL_STEP: 775\u001b[0m\n",
      "     | > loss: 3.22963809967041  (3.3145235566911984)\n",
      "     | > log_mle: 0.8491696119308472  (0.8561051429771795)\n",
      "     | > loss_dur: 2.3804686069488525  (2.4584184132294276)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.1958, device='cuda:0')  (tensor(8.6956, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 1.1084  (0.5361794281781205)\n",
      "     | > loader_time: 0.0113  (0.007883818168950273)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2023-07-25 17:23:18 -- STEP: 394/406 -- GLOBAL_STEP: 800\u001b[0m\n",
      "     | > loss: 3.2408947944641113  (3.3110734315087953)\n",
      "     | > log_mle: 0.8583637475967407  (0.8559877181113674)\n",
      "     | > loss_dur: 2.382530927658081  (2.45508571385127)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.1368, device='cuda:0')  (tensor(8.6654, device='cuda:0'))\n",
      "     | > current_lr: 2.5e-07 \n",
      "     | > step_time: 0.5704  (0.5434682623383965)\n",
      "     | > loader_time: 0.0087  (0.008081777446766185)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n",
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 0.07795578241348267 \u001b[0m(-0.03998485207557678)\n",
      "     | > avg_loss:\u001b[92m 3.271086573600769 \u001b[0m(-0.13235288858413696)\n",
      "     | > avg_log_mle:\u001b[92m 0.8498746827244759 \u001b[0m(-0.009380638599395752)\n",
      "     | > avg_loss_dur:\u001b[92m 2.421211898326874 \u001b[0m(-0.1229722797870636)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time: 0.07795578241348267 \u001b[0m(+0.0)\n",
      "     | > avg_loss: 3.271086573600769 \u001b[0m(+0.0)\n",
      "     | > avg_log_mle: 0.8498746827244759 \u001b[0m(+0.0)\n",
      "     | > avg_loss_dur: 2.421211898326874 \u001b[0m(+0.0)\n",
      "\n",
      " > BEST MODEL : /root/tts-output/run-July-25-2023_05+10PM-0000000/best_model_812.pth\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 2/1000\u001b[0m\n",
      " --> /root/tts-output/run-July-25-2023_05+10PM-0000000\n",
      "\n",
      "\u001b[1m > TRAINING (2023-07-25 17:23:37) \u001b[0m\n",
      "\n",
      "\u001b[1m   --> TIME: 2023-07-25 17:23:45 -- STEP: 13/406 -- GLOBAL_STEP: 825\u001b[0m\n",
      "     | > loss: 3.227701187133789  (3.2774199889256406)\n",
      "     | > log_mle: 0.8378933668136597  (0.8436014147905203)\n",
      "     | > loss_dur: 2.389807939529419  (2.4338185787200928)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.9824, device='cuda:0')  (tensor(8.0358, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.3046  (0.42044813816363996)\n",
      "     | > loader_time: 0.0052  (0.004366232798649714)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2023-07-25 17:23:55 -- STEP: 38/406 -- GLOBAL_STEP: 850\u001b[0m\n",
      "     | > loss: 3.280834197998047  (3.2419891984839184)\n",
      "     | > log_mle: 0.8466890454292297  (0.8456778228282928)\n",
      "     | > loss_dur: 2.434145212173462  (2.396311364675823)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(8.0347, device='cuda:0')  (tensor(7.9792, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.4674  (0.40422273937024567)\n",
      "     | > loader_time: 0.0035  (0.004027893668726873)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2023-07-25 17:24:07 -- STEP: 63/406 -- GLOBAL_STEP: 875\u001b[0m\n",
      "     | > loss: 3.237298011779785  (3.2251158933790904)\n",
      "     | > log_mle: 0.8444135785102844  (0.8460633868262881)\n",
      "     | > loss_dur: 2.3928844928741455  (2.3790524914151145)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.7920, device='cuda:0')  (tensor(7.9072, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.3668  (0.4294408767942398)\n",
      "     | > loader_time: 0.0082  (0.004679626888699002)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2023-07-25 17:24:18 -- STEP: 88/406 -- GLOBAL_STEP: 900\u001b[0m\n",
      "     | > loss: 3.1257877349853516  (3.213764030825008)\n",
      "     | > log_mle: 0.8452599048614502  (0.8461421457203951)\n",
      "     | > loss_dur: 2.2805278301239014  (2.3676218742674044)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.4438, device='cuda:0')  (tensor(7.8329, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.4239  (0.43741277673027734)\n",
      "     | > loader_time: 0.0046  (0.005111501975492999)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2023-07-25 17:24:30 -- STEP: 113/406 -- GLOBAL_STEP: 925\u001b[0m\n",
      "     | > loss: 3.1835999488830566  (3.200910464852257)\n",
      "     | > log_mle: 0.8458992838859558  (0.8460256093371231)\n",
      "     | > loss_dur: 2.337700605392456  (2.354884848130488)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.4008, device='cuda:0')  (tensor(7.7515, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.4723  (0.44500458767983764)\n",
      "     | > loader_time: 0.0038  (0.005593405360669163)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2023-07-25 17:24:43 -- STEP: 138/406 -- GLOBAL_STEP: 950\u001b[0m\n",
      "     | > loss: 3.2137627601623535  (3.197133029716602)\n",
      "     | > log_mle: 0.8426207304000854  (0.845558908538542)\n",
      "     | > loss_dur: 2.3711421489715576  (2.351574120314225)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.3859, device='cuda:0')  (tensor(7.6882, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.7124  (0.4580272332481716)\n",
      "     | > loader_time: 0.0047  (0.005665549333544746)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2023-07-25 17:24:57 -- STEP: 163/406 -- GLOBAL_STEP: 975\u001b[0m\n",
      "     | > loss: 3.135802745819092  (3.1934857500111398)\n",
      "     | > log_mle: 0.8427853584289551  (0.8449471183349754)\n",
      "     | > loss_dur: 2.2930173873901367  (2.348538629847802)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.1469, device='cuda:0')  (tensor(7.6277, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 1.0071  (0.4715266842052249)\n",
      "     | > loader_time: 0.0139  (0.0057566136670258875)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2023-07-25 17:25:11 -- STEP: 188/406 -- GLOBAL_STEP: 1000\u001b[0m\n",
      "     | > loss: 3.302715539932251  (3.189552853716181)\n",
      "     | > log_mle: 0.8434743285179138  (0.8443351029715642)\n",
      "     | > loss_dur: 2.4592411518096924  (2.3452177491593864)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(7.3140, device='cuda:0')  (tensor(7.5659, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.5246  (0.47919418583524986)\n",
      "     | > loader_time: 0.004  (0.006117153674998181)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2023-07-25 17:25:24 -- STEP: 213/406 -- GLOBAL_STEP: 1025\u001b[0m\n",
      "     | > loss: 3.0995612144470215  (3.18439269625525)\n",
      "     | > log_mle: 0.8355649709701538  (0.8436798679996547)\n",
      "     | > loss_dur: 2.2639963626861572  (2.3407128271362594)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.9018, device='cuda:0')  (tensor(7.5035, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.5101  (0.4818374383057787)\n",
      "     | > loader_time: 0.0112  (0.0062285734454231075)\n",
      "\n",
      "\n",
      "\u001b[1m   --> TIME: 2023-07-25 17:25:38 -- STEP: 238/406 -- GLOBAL_STEP: 1050\u001b[0m\n",
      "     | > loss: 3.1712937355041504  (3.180530093297237)\n",
      "     | > log_mle: 0.8380627632141113  (0.8431393338852572)\n",
      "     | > loss_dur: 2.333230972290039  (2.3373907544031867)\n",
      "     | > amp_scaler: 16384.0  (16384.0)\n",
      "     | > grad_norm: tensor(6.9415, device='cuda:0')  (tensor(7.4449, device='cuda:0'))\n",
      "     | > current_lr: 5e-07 \n",
      "     | > step_time: 0.4225  (0.48928692961941245)\n",
      "     | > loader_time: 0.0042  (0.006518548276244091)\n",
      "\n",
      " > Keyboard interrupt detected.\n",
      " > Saving model before exiting...\n",
      "\n",
      " > CHECKPOINT : /root/tts-output/run-July-25-2023_05+10PM-0000000/checkpoint_1057.pth\n",
      " ! Run is kept in /root/tts-output/run-July-25-2023_05+10PM-0000000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Trainer: Where the ‚ú®Ô∏è happens.\n",
    "# TrainingArgs: Defines the set of arguments of the Trainer.\n",
    "from trainer import Trainer, TrainerArgs\n",
    "\n",
    "# GlowTTSConfig: all model related values for training, validating and testing.\n",
    "from TTS.tts.configs.glow_tts_config import GlowTTSConfig\n",
    "\n",
    "# BaseDatasetConfig: defines name, formatter and path of the dataset.\n",
    "from TTS.tts.configs.shared_configs import BaseDatasetConfig\n",
    "from TTS.tts.datasets import load_tts_samples\n",
    "from TTS.tts.models.glow_tts import GlowTTS\n",
    "from TTS.tts.utils.text.tokenizer import TTSTokenizer\n",
    "from TTS.utils.audio import AudioProcessor\n",
    "\n",
    "# we use the same path as this script as our training folder.\n",
    "output_path = os.path.dirname(os.path.abspath('../../TTS'))\n",
    "\n",
    "# DEFINE DATASET CONFIG\n",
    "# Set LJSpeech as our target dataset and define its path.\n",
    "# You can also use a simple Dict to define the dataset and pass it to your custom formatter.\n",
    "dataset_config = BaseDatasetConfig(\n",
    "    formatter=\"ljspeech\", meta_file_train=\"metadata.csv\", path=os.path.join(output_path, \"LJSpeech-1.1/\")\n",
    ")\n",
    "\n",
    "# INITIALIZE THE TRAINING CONFIGURATION\n",
    "# Configure the model. Every config class inherits the BaseTTSConfig.\n",
    "config = GlowTTSConfig(\n",
    "    batch_size=32,\n",
    "    eval_batch_size=16,\n",
    "    num_loader_workers=4,\n",
    "    num_eval_loader_workers=4,\n",
    "    run_eval=True,\n",
    "    test_delay_epochs=-1,\n",
    "    epochs=1000,\n",
    "    text_cleaner=\"phoneme_cleaners\",\n",
    "    use_phonemes=True,\n",
    "    phoneme_language=\"en-us\",\n",
    "    phoneme_cache_path=os.path.join(output_path, \"phoneme_cache\"),\n",
    "    print_step=25,\n",
    "    print_eval=False,\n",
    "    mixed_precision=True,\n",
    "    output_path=output_path,\n",
    "    datasets=[dataset_config],\n",
    ")\n",
    "\n",
    "# INITIALIZE THE AUDIO PROCESSOR\n",
    "# Audio processor is used for feature extraction and audio I/O.\n",
    "# It mainly serves to the dataloader and the training loggers.\n",
    "ap = AudioProcessor.init_from_config(config)\n",
    "\n",
    "# INITIALIZE THE TOKENIZER\n",
    "# Tokenizer is used to convert text to sequences of token IDs.\n",
    "# If characters are not defined in the config, default characters are passed to the config\n",
    "tokenizer, config = TTSTokenizer.init_from_config(config)\n",
    "\n",
    "# LOAD DATA SAMPLES\n",
    "# Each sample is a list of ```[text, audio_file_path, speaker_name]```\n",
    "# You can define your custom sample loader returning the list of samples.\n",
    "# Or define your custom formatter and pass it to the `load_tts_samples`.\n",
    "# Check `TTS.tts.datasets.load_tts_samples` for more details.\n",
    "train_samples, eval_samples = load_tts_samples(\n",
    "    dataset_config,\n",
    "    eval_split=True,\n",
    "    eval_split_max_size=config.eval_split_max_size,\n",
    "    eval_split_size=config.eval_split_size,\n",
    ")\n",
    "\n",
    "# INITIALIZE THE MODEL\n",
    "# Models take a config object and a speaker manager as input\n",
    "# Config defines the details of the model like the number of layers, the size of the embedding, etc.\n",
    "# Speaker manager is used by multi-speaker models.\n",
    "model = GlowTTS(config, ap, tokenizer, speaker_manager=None)\n",
    "\n",
    "# INITIALIZE THE TRAINER\n",
    "# Trainer provides a generic API to train all the üê∏TTS models with all its perks like mixed-precision training,\n",
    "# distributed training, etc.\n",
    "trainer = Trainer(\n",
    "    TrainerArgs(), config, output_path, model=model, train_samples=train_samples, eval_samples=eval_samples\n",
    ")\n",
    "\n",
    "# AND... 3,2,1... üöÄ\n",
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3d5514-fcce-4ea8-a000-f724f9e019e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
